{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zcf-cFyhkptD"
   },
   "source": [
    "# Data exploration and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "B1vL4GiFdFPG"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcondbert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CondBertRewriter\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchoosers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingSimilarityChooser\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmasked_token_predictor_bert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaskedTokenPredictorBert\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import BertTokenizer, BertForMaskedLM, BertTokenizerFast\n",
    "\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "import re\n",
    "import os\n",
    "\n",
    "from models.condbert import CondBertRewriter\n",
    "from models.choosers import EmbeddingSimilarityChooser\n",
    "from models.masked_token_predictor_bert import MaskedTokenPredictorBert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from flair.data import Sentence\n",
    "from flair.embeddings import WordEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, create and show image with half size in both axis with original ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('filtered.tsv', sep='\\t')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>Now what else did the prostitute say?</td>\n",
       "      <td>what else did the bride say?</td>\n",
       "      <td>0.725349</td>\n",
       "      <td>0.236842</td>\n",
       "      <td>0.978869</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>I'm gonna spew.</td>\n",
       "      <td>I'll puke.</td>\n",
       "      <td>0.699393</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.088549</td>\n",
       "      <td>0.978189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>\"He is that,\" said Estraven, \"but I asked too ...</td>\n",
       "      <td>\"he's a traitor,\" Estraven told me, \"but I ask...</td>\n",
       "      <td>0.693783</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.964762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>Hello, new dice smell.</td>\n",
       "      <td>hey, the smell of new tits.</td>\n",
       "      <td>0.647981</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.993284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>If I see you again in Rome, it'll be on the po...</td>\n",
       "      <td>if I'm to see you in Rome, it will be \"somethi...</td>\n",
       "      <td>0.771230</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.549475</td>\n",
       "      <td>0.006484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reference  \\\n",
       "0      If Alkar is flooding her with psychic waste, t...   \n",
       "1                              Now you're getting nasty.   \n",
       "2               Well, we could spare your life, for one.   \n",
       "3              Ah! Monkey, you've got to snap out of it.   \n",
       "4                       I've got orders to put her down.   \n",
       "...                                                  ...   \n",
       "19995              Now what else did the prostitute say?   \n",
       "19996                                    I'm gonna spew.   \n",
       "19997  \"He is that,\" said Estraven, \"but I asked too ...   \n",
       "19998                             Hello, new dice smell.   \n",
       "19999  If I see you again in Rome, it'll be on the po...   \n",
       "\n",
       "                                             translation  similarity  \\\n",
       "0      if Alkar floods her with her mental waste, it ...    0.785171   \n",
       "1                            you're becoming disgusting.    0.749687   \n",
       "2                          well, we can spare your life.    0.919051   \n",
       "3                           monkey, you have to wake up.    0.664333   \n",
       "4                             I have orders to kill her.    0.726639   \n",
       "...                                                  ...         ...   \n",
       "19995                       what else did the bride say?    0.725349   \n",
       "19996                                         I'll puke.    0.699393   \n",
       "19997  \"he's a traitor,\" Estraven told me, \"but I ask...    0.693783   \n",
       "19998                        hey, the smell of new tits.    0.647981   \n",
       "19999  if I'm to see you in Rome, it will be \"somethi...    0.771230   \n",
       "\n",
       "       lenght_diff   ref_tox   trn_tox  \n",
       "0         0.010309  0.014195  0.981983  \n",
       "1         0.071429  0.065473  0.999039  \n",
       "2         0.268293  0.213313  0.985068  \n",
       "3         0.309524  0.053362  0.994215  \n",
       "4         0.181818  0.009402  0.999348  \n",
       "...            ...       ...       ...  \n",
       "19995     0.236842  0.978869  0.000040  \n",
       "19996     0.312500  0.088549  0.978189  \n",
       "19997     0.061224  0.000046  0.964762  \n",
       "19998     0.178571  0.000183  0.993284  \n",
       "19999     0.100000  0.549475  0.006484  \n",
       "\n",
       "[20000 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)\n",
    "dataset = df.copy()\n",
    "dataset = dataset.head(20000)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5416104048595838 0.43504418545919943\n"
     ]
    }
   ],
   "source": [
    "aboba1 = np.mean(dataset[\"ref_tox\"])\n",
    "aboba2 = np.mean(dataset[\"trn_tox\"])\n",
    "print(aboba1, aboba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dataset.index:\n",
    "    if dataset.loc[i, 'trn_tox'] >= 0.5:\n",
    "        # Swap 'reference' and 'translation'\n",
    "        dataset.loc[i, 'reference'], dataset.loc[i, 'translation'] = dataset.loc[i, 'translation'], dataset.loc[i, 'reference']\n",
    "        \n",
    "        # Swap 'ref_tox' and 'trn_tox'\n",
    "        dataset.loc[i, 'ref_tox'], dataset.loc[i, 'trn_tox'] = dataset.loc[i, 'trn_tox'], dataset.loc[i, 'ref_tox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9400417279332877 0.036612862385495604\n"
     ]
    }
   ],
   "source": [
    "aboba1 = np.mean(dataset[\"ref_tox\"])\n",
    "aboba2 = np.mean(dataset[\"trn_tox\"])\n",
    "print(aboba1, aboba2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"reference\"].iloc[:20000].tolist()\n",
    "labels = (df[\"ref_tox\"].iloc[:20000] >= 0.5).astype(int).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fatuous Xerxes blithely surrendered control to the computer grid, ordering it to take care of whatever troubles might arise.', \"That night, Li'l Dice satisfied his thirst to kill, though he knew Shaggy would never forgive him.\", 'Real life starts the first time you fuck, kid.', \"I think you are the strangest man I've ever met.\", \"I say creepy, I mean, it's totally batshit crazy I can even talk to you.\", \"Shit, this one I can't even pronounce.\", 'I like that shit.', \"Trying to keep me fucking drugged so I don't know what's going on.\", 'How is this not porn? This is porn that comes home.', 'Hey, leave the poor bastard alone!']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0, 0, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(texts[20:30])\n",
    "labels[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "C:\\Users\\markz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Assuming 'texts' is your list of texts and 'labels' is your list of toxicity labels\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Train the logistic regression model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X, labels)\n",
    "\n",
    "# Get the feature names (words) and their weights from the logistic regression model\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "feature_weights = lr_model.coef_[0]\n",
    "\n",
    "# Create a dictionary mapping words to their toxicity scores (weights)\n",
    "word_toxicity_scores = dict(zip(feature_names, feature_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for each sentence in 'texts', compute the toxicity score for each word and find the toxic words\n",
    "toxic_words_in_sentences = []\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    # Split the sentence into words, considering punctuation\n",
    "    words = re.findall(r'\\b\\w+\\b', texts[i])\n",
    "    \n",
    "    # Compute the toxicity scores for the words\n",
    "    scores = [word_toxicity_scores.get(word, 0) for word in words]\n",
    "    \n",
    "    # Compute the threshold\n",
    "    t = max(0.2, max(scores)/2)\n",
    "    \n",
    "    # Find the toxic words\n",
    "    toxic_words = [word for word, score in zip(words, scores) if score > t]\n",
    "    \n",
    "    toxic_words_in_sentences.append(toxic_words)\n",
    "toxic_words_in_sentences = [item for sublist in toxic_words_in_sentences for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'00': -1.250372381536675,\n",
       " '000': -0.06775326951346249,\n",
       " '05': 0.0024472439507403645,\n",
       " '0ne': -0.06306058166157542,\n",
       " '0r': 0.30697074899817106,\n",
       " '0um': -0.10849973932604541,\n",
       " '10': 0.4457266956141903,\n",
       " '100': 0.19083089630205974,\n",
       " '1000': 0.002718057516265926,\n",
       " '106': 0.018801527289510542,\n",
       " '11': 0.016283183744113125,\n",
       " '111': -0.1666382048057594,\n",
       " '12': 0.24316221405171637,\n",
       " '125': 0.019140219920416864,\n",
       " '13': 0.3568961175276489,\n",
       " '14': -0.10330965650432955,\n",
       " '15': -0.15942082482478764,\n",
       " '150': -0.09298847216025222,\n",
       " '157': 0.364261145498049,\n",
       " '16': -0.6946483404891742,\n",
       " '160': 0.37501826313474396,\n",
       " '16th': -0.25716396324733704,\n",
       " '17': -0.18415811468507468,\n",
       " '18': 0.2723239852781559,\n",
       " '1820': -0.026815669192258248,\n",
       " '18th': -0.05486810958425707,\n",
       " '19': 0.02313261340121962,\n",
       " '1948': 0.21326929137296713,\n",
       " '1955': -0.047302450938045824,\n",
       " '1959': -0.07223563951093512,\n",
       " '1973': -0.1774444220131933,\n",
       " '1975': 0.06013112893421485,\n",
       " '1978': 0.13949746054756898,\n",
       " '1980': 0.16547441312593356,\n",
       " '1989': -0.0877468527353783,\n",
       " '1990': -0.0877468527353783,\n",
       " '1st': 0.15523039133421204,\n",
       " '20': 0.37106318226780105,\n",
       " '200': 0.32580960987812313,\n",
       " '20th': -0.16766933521885158,\n",
       " '21': -0.12091204168370046,\n",
       " '21st': -0.004917522893245001,\n",
       " '22': 0.6158442725311825,\n",
       " '220': 0.019472490897202124,\n",
       " '23': -0.36641348981050476,\n",
       " '24': -0.09532820449717914,\n",
       " '25': -0.37335487564545666,\n",
       " '250': 0.18171644458577652,\n",
       " '2500': 0.093796193540554,\n",
       " '25s': 0.06755269403813681,\n",
       " '25th': 0.0017357030794948095,\n",
       " '26': 0.18022071508633025,\n",
       " '27': 0.35426791505715477,\n",
       " '2girls1cup': 0.04774022892006698,\n",
       " '2s': -0.3598295393262834,\n",
       " '30': 0.6084499865358296,\n",
       " '300': -0.3576603672799844,\n",
       " '30th': 0.0024472439507403645,\n",
       " '31': 0.010199182467732933,\n",
       " '35': -0.3287707544107996,\n",
       " '357': 0.366479476237215,\n",
       " '36': 0.07496201290077838,\n",
       " '38': -0.19298802701217815,\n",
       " '39c': 0.4059478522247839,\n",
       " '3rd': -0.49958474132079417,\n",
       " '3s': -0.3598295393262834,\n",
       " '3½': -0.08758989890910589,\n",
       " '40': 0.36529044226864316,\n",
       " '400': 0.0019124627600455675,\n",
       " '4000': -0.13753655538534312,\n",
       " '40s': 0.005415061823556768,\n",
       " '425': -0.17404442788752258,\n",
       " '43': -0.10573261008587641,\n",
       " '430': -0.07658960861845707,\n",
       " '45': 0.400204663791121,\n",
       " '45th': 0.005837363436099072,\n",
       " '474': -0.13456023790305127,\n",
       " '48': -0.10856644778486334,\n",
       " '4th': 0.303324862253383,\n",
       " '50': -1.3239398743051882,\n",
       " '500': 0.28633959239799145,\n",
       " '5000': 0.15971598353762947,\n",
       " '50s': 0.33390851284108714,\n",
       " '53': 0.47061978972578894,\n",
       " '60': -0.5925329410751075,\n",
       " '600': 0.13594452870255763,\n",
       " '68': 0.06487118135365688,\n",
       " '69': 0.06233733926545924,\n",
       " '70': -0.530548253622461,\n",
       " '70s': 0.07606422524513283,\n",
       " '75': -0.09298847216025222,\n",
       " '785': 0.00755417390701778,\n",
       " '7i': -0.1518133113474323,\n",
       " '7th': 0.05440059243593173,\n",
       " '80': -0.22373972550043172,\n",
       " '800': 0.1398629932402099,\n",
       " '80s': 0.14527143184973362,\n",
       " '82': -0.1986598220713876,\n",
       " '85': 0.4226539835109142,\n",
       " '88': 0.006060079353598451,\n",
       " '90': 0.3760576777415193,\n",
       " '911': -0.5701442296740271,\n",
       " '97': 0.03222253842595768,\n",
       " '99': -0.06471878882151333,\n",
       " '9th': 0.3270079783280083,\n",
       " '_like_': 0.14044806342771377,\n",
       " '_oomar': -0.33043000560425206,\n",
       " '_paraffine_': 0.5966579026450767,\n",
       " 'aaahhh': -0.2470261872321404,\n",
       " 'aah': 0.19588314210366223,\n",
       " 'aahz': 0.03063841872823811,\n",
       " 'aaron': 0.40285676904482937,\n",
       " 'abandon': -0.07808036708130667,\n",
       " 'abandoned': -0.8921460388804516,\n",
       " 'abarrach': 0.07425512394430889,\n",
       " 'abbey': -0.11377838328074132,\n",
       " 'abby': -0.24267810902504963,\n",
       " 'abdo': -0.0626640966642796,\n",
       " 'abdomen': -0.16797034185103618,\n",
       " 'abducted': -0.24114576134763652,\n",
       " 'abducting': -0.14457199732840328,\n",
       " 'abe': -0.20429520084924688,\n",
       " 'abed': 0.23809405231411027,\n",
       " 'abel': -0.11970151056341244,\n",
       " 'aberrant': 0.1267380910305883,\n",
       " 'aberration': -0.21176504000090243,\n",
       " 'abhorred': -0.2011127344580597,\n",
       " 'abigail': 0.005236243633052963,\n",
       " 'abilities': -0.3678011998816502,\n",
       " 'ability': 0.036282921773244034,\n",
       " 'abiru': 0.25625348019412136,\n",
       " 'abitch': -0.21969199206739576,\n",
       " 'able': -0.633620278882272,\n",
       " 'abner': 0.025473680078664736,\n",
       " 'abnormality': -0.14469035513975587,\n",
       " 'aboard': 0.4894649467904183,\n",
       " 'abomination': 0.12969027717949516,\n",
       " 'abominations': 0.26880300003348295,\n",
       " 'abort': -0.16813574448187252,\n",
       " 'aborted': -0.11965817258046017,\n",
       " 'abortion': -0.26313115428384337,\n",
       " 'about': -0.2440963951791081,\n",
       " 'aboutthe': 0.026400139870213658,\n",
       " 'abouttwo': -0.34476851447445045,\n",
       " 'aboutyou': -0.08942187749354895,\n",
       " 'above': -0.5256320680469059,\n",
       " 'abraham': -0.10878006183258956,\n",
       " 'abrasive': 0.18686476149432854,\n",
       " 'abraxas': 0.04395238120900525,\n",
       " 'abroad': -0.16459071835231004,\n",
       " 'abrupt': -0.23376959806473271,\n",
       " 'abs': -0.3865987062355248,\n",
       " 'absence': -0.20734300115874366,\n",
       " 'absently': 0.04962915085291707,\n",
       " 'abshir': 0.31535927237289935,\n",
       " 'absolute': 0.37692143385125476,\n",
       " 'absolutely': -0.2867251295964744,\n",
       " 'absorbed': -0.2722180651284623,\n",
       " 'abstinence': -0.13839598947842505,\n",
       " 'abstract': -0.19938869167018536,\n",
       " 'absurd': -1.4902438085333884,\n",
       " 'absurdity': -0.32035956562726625,\n",
       " 'abu': -0.10849973932604541,\n",
       " 'abundance': -0.2686483615105312,\n",
       " 'abuse': -0.24257464039365237,\n",
       " 'abused': 0.31791923439186526,\n",
       " 'abuser': -0.1891606634026431,\n",
       " 'abuses': 0.053161731839236885,\n",
       " 'abusing': 0.175880951976417,\n",
       " 'abusive': -0.4382205257756566,\n",
       " 'academic': 0.3358052635388844,\n",
       " 'academy': 0.6320046790175884,\n",
       " 'accelerator': -0.11105794931239542,\n",
       " 'accent': -0.5177125182690655,\n",
       " 'accents': 0.008879025478587594,\n",
       " 'accept': 0.5980762644085408,\n",
       " 'acceptable': -0.04946798855890163,\n",
       " 'accepted': 0.10124197090852123,\n",
       " 'access': -0.3937647284695141,\n",
       " 'accessory': 0.3416510135166156,\n",
       " 'accident': -0.27072866585670147,\n",
       " 'accidentally': -0.5196981218582649,\n",
       " 'accidents': -0.22165025635377883,\n",
       " 'accompanied': -0.09464459697165963,\n",
       " 'accomplices': -0.057245037521537104,\n",
       " 'accomplish': -0.23518369140762646,\n",
       " 'accomplished': 0.21961201540544162,\n",
       " 'accomplishments': 0.25626638885490205,\n",
       " 'accordance': -0.3520408185122337,\n",
       " 'according': -0.7664673829411273,\n",
       " 'accosted': -0.12011642139686438,\n",
       " 'account': -0.13048938818250894,\n",
       " 'accountable': -0.30174003543587474,\n",
       " 'accounting': -0.3976310910134609,\n",
       " 'accounts': 0.1935222551262699,\n",
       " 'accrued': 0.0917082083700075,\n",
       " 'accumulation': 0.004973117538667599,\n",
       " 'accuracy': 0.19058177404162202,\n",
       " 'accurate': 0.4239151774713626,\n",
       " 'accurately': -0.09298847216025222,\n",
       " 'accursed': -0.2916503861018793,\n",
       " 'accusations': 0.07244071739863976,\n",
       " 'accused': 0.22936206424984484,\n",
       " 'accuses': 0.001209656530793949,\n",
       " 'accusing': 0.5652879056479949,\n",
       " 'accustomed': 0.08541627643739146,\n",
       " 'ace': -0.020600212975732342,\n",
       " 'ache': 0.010820261443460648,\n",
       " 'ached': 0.2849348712790828,\n",
       " 'aching': -0.08532369432641126,\n",
       " 'acid': 0.5469659883905355,\n",
       " 'ackerman': -0.5918562581336894,\n",
       " 'ackley': 0.005404809420365125,\n",
       " 'acknowledgment': -0.05310630929615836,\n",
       " 'acne': -0.1009709677734014,\n",
       " 'acquainted': 0.1562642219389884,\n",
       " 'acquired': -0.08323540719748991,\n",
       " 'across': -0.014527341770766845,\n",
       " 'act': -0.5619240823834042,\n",
       " 'acted': 0.12807912049894662,\n",
       " 'acting': -0.7894074573687324,\n",
       " 'action': 0.005302392850665809,\n",
       " 'actions': -0.17986609945852738,\n",
       " 'activating': -0.24649355962294556,\n",
       " 'active': -0.01413381216085056,\n",
       " 'activists': -0.154429645687181,\n",
       " 'activity': -0.09681624673967204,\n",
       " 'actly': -0.09147760597259462,\n",
       " 'actor': 0.3465503384386117,\n",
       " 'actors': 0.3554030126465655,\n",
       " 'actress': 0.07234753016784957,\n",
       " 'acts': -0.00551730716314789,\n",
       " 'actual': -0.0443162039702599,\n",
       " 'actually': -0.2797182886967536,\n",
       " 'acutely': 0.29620694109333484,\n",
       " 'ad': 0.31596424041706506,\n",
       " 'adam': 0.22784617853707984,\n",
       " 'adama': 0.026362390634516338,\n",
       " 'adapt': 0.11278943184687092,\n",
       " 'adapter': 0.004692445470142389,\n",
       " 'adc': 0.11358466433095221,\n",
       " 'add': 0.46603030275501517,\n",
       " 'addams': 0.016443863093052846,\n",
       " 'added': 0.12521251472838357,\n",
       " 'addict': 0.08989780729253054,\n",
       " 'addicted': -0.6871441956941537,\n",
       " 'addiction': -0.3252128911907474,\n",
       " 'addicts': -0.5060235026234124,\n",
       " 'addition': -0.2151731772792965,\n",
       " 'additional': -0.034788002266779035,\n",
       " 'addled': -0.09988480281734455,\n",
       " 'addons': -0.17253648432238342,\n",
       " 'address': -0.4088583343165503,\n",
       " 'addressbook': 0.22291703781017116,\n",
       " 'addresses': 0.15356275233319075,\n",
       " 'adds': 0.20028893490234692,\n",
       " 'adele': 0.2900020694110992,\n",
       " 'aditi': -0.18495538713559792,\n",
       " 'aditya': 0.05034210944361285,\n",
       " 'adjunct': 0.04850601833746213,\n",
       " 'adjust': 0.05238570990558298,\n",
       " 'adjusting': 0.11857471610048874,\n",
       " 'adler': 0.3587308879498933,\n",
       " 'adm': 0.17678804107257587,\n",
       " 'administer': 0.5951508127591825,\n",
       " 'administrator': -0.35244985884192176,\n",
       " 'admiral': 0.3206149855915873,\n",
       " 'admirals': -0.16645521918166079,\n",
       " 'admired': -0.020392987568231526,\n",
       " 'admit': -0.15478471128245888,\n",
       " 'admits': -0.37663873855743746,\n",
       " 'admittance': 0.37039458053654245,\n",
       " 'admitted': -0.2429656098116427,\n",
       " 'adobe': -0.27760342426654216,\n",
       " 'adolescent': 0.1784055018397522,\n",
       " 'adolf': -0.19197514062312748,\n",
       " 'adopt': -0.007192843549358144,\n",
       " 'adopted': 0.25404034844218465,\n",
       " 'adorable': -0.31614584561785725,\n",
       " 'adornment': 0.13289395725329406,\n",
       " 'adrenal': 0.5848416372306908,\n",
       " 'adrenaline': 0.19132509231092545,\n",
       " 'adrian': 0.03141003265886163,\n",
       " 'adult': -0.048564364767793224,\n",
       " 'adultery': -0.34189056110034005,\n",
       " 'adults': -0.2103845055892441,\n",
       " 'advantage': 0.10335285575964463,\n",
       " 'advantageous': -0.1592797473357386,\n",
       " 'adventure': 0.2049457069941077,\n",
       " 'adventurer': 0.21068898425148916,\n",
       " 'adventurousness': -0.3262843308087406,\n",
       " 'adversary': -0.14119453978214103,\n",
       " 'advice': 0.09392613551495622,\n",
       " 'advise': 0.0775476918140352,\n",
       " 'advisor': 0.0009084513200512314,\n",
       " 'advocate': -0.03230991354577795,\n",
       " 'aerodyne': 0.15522584327410413,\n",
       " 'aeryn': -0.6858034809867452,\n",
       " 'aesthetician': 0.42390224367456336,\n",
       " 'afar': -0.1552424518466549,\n",
       " 'affair': -0.58247300009757,\n",
       " 'affairs': -0.19428993230157532,\n",
       " 'affect': -0.2688417564813101,\n",
       " 'affected': 0.061665567862428446,\n",
       " 'affecting': -0.08586890279143534,\n",
       " 'affectionately': 0.46112869726988254,\n",
       " 'affections': -0.141223616421373,\n",
       " 'affixing': -0.1815250708465029,\n",
       " 'afford': 0.3772973602317175,\n",
       " 'afghanistan': -0.2690450092078899,\n",
       " 'aflame': 0.6632229930631287,\n",
       " 'afraid': 0.7731497193239134,\n",
       " 'africa': -0.3431783022749437,\n",
       " 'african': -0.856826457327717,\n",
       " 'after': 0.018509202084278958,\n",
       " 'afternoon': 0.18926997616836289,\n",
       " 'afternoons': -0.10681936912627797,\n",
       " 'afterwards': -0.7623553672993071,\n",
       " 'again': 0.07421347356432427,\n",
       " 'against': 0.1291838702857094,\n",
       " 'age': -0.6058263121265451,\n",
       " 'aged': 0.4990909396230426,\n",
       " 'agencies': 0.003621021813856352,\n",
       " 'agency': -0.1298027934101415,\n",
       " 'agent': -0.41316022218788173,\n",
       " 'agents': -0.17423799379999497,\n",
       " 'ages': -0.05486810958425707,\n",
       " 'agger': -0.30117504437237114,\n",
       " 'aggravated': -0.17631201976702252,\n",
       " 'aggressions': 0.089504012792623,\n",
       " 'aggressive': 0.014067009308113875,\n",
       " 'agitated': -0.15742741022180082,\n",
       " 'agnes': 0.051361669731522036,\n",
       " 'ago': -0.8642571738853476,\n",
       " 'agonies': -0.20003719097775538,\n",
       " 'agonizing': -0.17170648793385232,\n",
       " 'agony': -0.4259224003776589,\n",
       " 'agosta': -0.12753327916224275,\n",
       " 'agree': -0.6991506672536889,\n",
       " 'agreed': 0.08313056620574431,\n",
       " 'agreement': -0.10201687442213406,\n",
       " 'ah': -0.45633117919530797,\n",
       " 'ahead': -0.25782635042205176,\n",
       " 'ahh': -0.12672690276933415,\n",
       " 'ahmed': 0.2804757550403304,\n",
       " 'aid': 0.26979288861141715,\n",
       " 'aidan': -0.36193491676185646,\n",
       " 'aide': 0.24999210005877665,\n",
       " 'aidid': 0.08674317276948847,\n",
       " 'aids': -0.4230170889981317,\n",
       " 'aigoo': -0.4632210447802228,\n",
       " 'ailing': -0.17459024445612686,\n",
       " 'aim': 0.2893801615605745,\n",
       " 'aimed': 0.023476113776985823,\n",
       " 'aiming': -0.35434913535511825,\n",
       " 'ain': -0.005416523267897553,\n",
       " 'air': -0.21201958779912014,\n",
       " 'airborne': 0.040373562471490744,\n",
       " 'airhead': 0.0347913830313011,\n",
       " 'airplane': -0.29048823438263355,\n",
       " 'airplanes': 0.12345976036211943,\n",
       " 'airport': 0.16424507158120996,\n",
       " 'airports': 0.20221366308178093,\n",
       " 'airs': -0.1561739857686916,\n",
       " 'airways': 0.035177025316465084,\n",
       " 'aisle': 0.20816548715895478,\n",
       " 'ajax': 0.2817658601939262,\n",
       " 'aka': 0.09517183036786744,\n",
       " 'akizuki': 0.292798267275829,\n",
       " 'akmans': 0.25221943438162514,\n",
       " 'akon': 0.04774022892006698,\n",
       " 'al': -0.3473770936510065,\n",
       " 'alabama': -0.036587721113047644,\n",
       " 'alacrity': 0.29385938028350145,\n",
       " 'alak': -0.4851530589311044,\n",
       " 'alan': 0.18510777939075831,\n",
       " 'alana': 0.16421976099643926,\n",
       " 'alarm': 0.06241800627017341,\n",
       " 'alas': 0.3566127965664898,\n",
       " 'albatross': -0.4111754948976412,\n",
       " 'albeit': 0.005075866691354178,\n",
       " 'albert': 0.3208295453004027,\n",
       " 'albion': -0.23625405029918073,\n",
       " 'albright': 0.004186929675859858,\n",
       " 'album': -0.9061845538435572,\n",
       " 'albuquerque': -0.13796620789175978,\n",
       " 'alby': 0.22223612139932286,\n",
       " 'alchemical': -0.02670511091868569,\n",
       " 'alchemist': 0.375838445443389,\n",
       " 'alcohol': -0.025915918074703476,\n",
       " 'alcoholic': -0.21747366785435068,\n",
       " 'alden': 0.3798555794785836,\n",
       " 'alderman': -0.2686483615105312,\n",
       " 'ale': -0.3666553480434211,\n",
       " 'alec': -0.42097061510220074,\n",
       " 'aleck': -0.19589322806979592,\n",
       " 'aleida': 0.024284614989496328,\n",
       " 'alejandro': 0.21393268727889714,\n",
       " 'alekseyev': 0.01997659361407982,\n",
       " 'alert': -0.4152532141655641,\n",
       " 'alex': -0.7060890897709505,\n",
       " 'alexander': -0.2642731065126076,\n",
       " 'alexandra': -0.31814586669179884,\n",
       " 'alexandria': 0.3878639295909921,\n",
       " 'alfie': 0.12270006204112845,\n",
       " 'alfonso': -0.07757013351693684,\n",
       " 'alfred': -0.21276100700180223,\n",
       " 'ali': -0.4410411337851194,\n",
       " 'alia': -0.09826872692726828,\n",
       " 'alibi': -0.16568793286280298,\n",
       " 'alice': -0.6414985563920399,\n",
       " 'alicia': -0.20575266133877332,\n",
       " 'alien': 0.8100577809890077,\n",
       " 'alienating': -0.13950245614479154,\n",
       " 'aliens': -0.49208630334037107,\n",
       " 'alight': 0.15387359111705332,\n",
       " 'aligned': 0.04297675682113,\n",
       " 'alike': 0.2017940836932927,\n",
       " 'alistair': 0.29298742611336204,\n",
       " 'alive': 0.21737630559333682,\n",
       " 'alkar': -0.23435640722257026,\n",
       " 'all': 0.12509242958900102,\n",
       " 'all2gethr': -0.17253648432238342,\n",
       " 'allan': 0.024066286281562797,\n",
       " 'allegiance': 0.15255195791136578,\n",
       " 'allen': -0.35969850184141106,\n",
       " 'alley': 0.6184157882957064,\n",
       " 'alleys': 0.1095176106357035,\n",
       " 'alliance': -0.11302311520398985,\n",
       " 'allies': 0.5114750611997978,\n",
       " 'alligators': 0.0046130881189798455,\n",
       " 'allison': -0.5244173863973505,\n",
       " 'allow': 0.25720242592952564,\n",
       " 'allowance': -0.21460108961901178,\n",
       " 'allowed': -0.36442962334221196,\n",
       " 'allowing': 0.5130543769616372,\n",
       " 'allows': -0.5522365560220477,\n",
       " 'alls': -0.2486867060216904,\n",
       " 'allshard': -0.13749025014406824,\n",
       " 'almighty': -0.13335220643782808,\n",
       " 'almost': -0.19220904441981765,\n",
       " 'alone': -0.0025008401249810895,\n",
       " 'along': -0.15615767048874368,\n",
       " 'alongside': 0.3226242625320745,\n",
       " 'alorns': -0.13494610272094407,\n",
       " 'aloud': -0.171213151658791,\n",
       " 'alphabet': -0.21631095542432147,\n",
       " 'alphabrotical': 0.06102026269084135,\n",
       " 'alphas': 0.5173323843244072,\n",
       " 'alphonse': 0.14376818793881505,\n",
       " 'already': 0.13804681389677587,\n",
       " 'alright': 0.2254264965789903,\n",
       " 'also': -0.021439907881175745,\n",
       " 'altar': -0.23769964420954426,\n",
       " 'altars': 0.5743268289401852,\n",
       " 'alter': -0.21155616988931344,\n",
       " 'alternate': 0.4130384749050119,\n",
       " 'alternately': -0.0324118233483208,\n",
       " 'alternative': -0.40977136224759014,\n",
       " 'although': -0.07086204886966659,\n",
       " 'alto': 0.005302392850665809,\n",
       " 'altogether': 0.05067698098854255,\n",
       " 'alvin': 0.24785035852380774,\n",
       " 'always': 0.15525232860002094,\n",
       " 'alyse': 0.004372198690338468,\n",
       " 'alzheimer': -0.27995866430618793,\n",
       " 'am': -0.22063428687714562,\n",
       " 'amalgam': -0.017974965343190336,\n",
       " 'amanda': 0.3313026021678302,\n",
       " 'amaretto': 0.08812514520582948,\n",
       " 'amarillo': 0.02204101399099325,\n",
       " 'amateur': 0.28633686694692845,\n",
       " 'amateurs': -0.055791952977498546,\n",
       " 'amazed': -0.24578500430930375,\n",
       " 'amazement': 0.11512954172484183,\n",
       " 'amazing': 0.0943263353039278,\n",
       " 'amazingly': 0.36623854470066464,\n",
       " 'ambare': -0.1276200791515294,\n",
       " 'ambassador': -0.16645521918166079,\n",
       " 'amber': 0.274562001672295,\n",
       " 'ambiguous': -0.038890126439873,\n",
       " 'ambition': 0.02657401632433933,\n",
       " 'ambulance': 0.25330000089959154,\n",
       " 'ambushed': -0.30639656531387566,\n",
       " 'ameba': 0.08367078454556257,\n",
       " 'amedeo': 0.397180745808695,\n",
       " 'amelia': 0.2500155773541037,\n",
       " 'amelie': -0.10144618315455535,\n",
       " 'amen': -0.4476875522299165,\n",
       " 'amenable': 0.005642730941664247,\n",
       " 'america': 0.019495857989639674,\n",
       " 'american': 0.9968773896067631,\n",
       " 'americana': -0.08437621985547607,\n",
       " 'americano': 0.15879657131399483,\n",
       " 'americans': -0.11553326197962092,\n",
       " 'americas': 0.2015606717230588,\n",
       " 'amerie': 0.3596588608761677,\n",
       " 'amico': 0.4722867452020487,\n",
       " 'amid': -0.05674235694072586,\n",
       " 'amin': 0.3055606346116281,\n",
       " 'ammo': 0.23381358487814072,\n",
       " 'ammonia': -0.18597694432050443,\n",
       " 'amnesia': -0.2715091300835083,\n",
       " 'amnesty': -0.26213732007376894,\n",
       " 'amok': -0.3534607197381129,\n",
       " 'among': 0.35635988186101164,\n",
       " 'amongst': -0.20175184297562537,\n",
       " 'amount': -0.41123513423692615,\n",
       " 'amounting': -0.07787064371847266,\n",
       " 'amounts': -0.25775069566200987,\n",
       " 'amped': -0.06314361391830034,\n",
       " 'amperage': -0.13645265398648349,\n",
       " 'amphibious': -0.26875800836744723,\n",
       " 'ample': 0.08421033400761699,\n",
       " 'amps': 0.0063750905098299325,\n",
       " 'amputate': 0.4638487281012066,\n",
       " 'amputation': -0.17519751702990663,\n",
       " 'amsterdam': 0.021438236577807777,\n",
       " 'amstw': -0.037661894989800965,\n",
       " 'amty': -0.15304726812039998,\n",
       " 'amused': 0.03796393575547057,\n",
       " 'amusing': -0.3440857708841258,\n",
       " 'amy': -0.14384468525371233,\n",
       " 'an': 0.2347184625505004,\n",
       " 'anal': 0.5511395068290436,\n",
       " 'analysis': -0.33002364108782756,\n",
       " 'anarchistic': 0.19803900108723044,\n",
       " 'anarchists': -0.09147087082180505,\n",
       " 'anawalt': 0.004645182794883139,\n",
       " 'ancestors': -0.3460345880965941,\n",
       " 'ancestry': -0.09147087082180505,\n",
       " 'anchor': 0.03561434493178609,\n",
       " 'anchors': -0.14391159708697987,\n",
       " 'ancient': 0.365827470015867,\n",
       " 'and': -0.0830776286475613,\n",
       " 'anddamned': 0.2733731391328984,\n",
       " 'anddrinking': -0.022569370339610637,\n",
       " 'anders': -0.2177611689980801,\n",
       " 'anderson': 0.04774022892006698,\n",
       " 'andie': 0.16990177924417177,\n",
       " 'andrea': 0.08563027851543681,\n",
       " 'androgynous': 0.3478016620722617,\n",
       " 'android': 0.01295681730137587,\n",
       " 'andwe': 0.10410768083739834,\n",
       " 'andy': 0.13707367926469435,\n",
       " 'anfo': 0.018356138739782438,\n",
       " 'angarak': 0.29480215947605504,\n",
       " 'angel': 0.4452593517497581,\n",
       " 'angela': 0.0009830751196259993,\n",
       " 'angeles': -0.35780701008029536,\n",
       " 'angelina': 0.07169052310025988,\n",
       " 'angelique': 0.09345151719504687,\n",
       " 'angels': 0.19590319073156243,\n",
       " 'anger': -0.07687763482001751,\n",
       " 'angie': -0.44523419375769957,\n",
       " 'angle': 0.30749225804750785,\n",
       " 'angles': 0.035025076671837845,\n",
       " 'angry': -0.7503091850894937,\n",
       " 'anguish': 0.2833402956446323,\n",
       " 'angus': -0.20409289310145,\n",
       " 'anibal': 0.015349858628832962,\n",
       " 'animal': 0.5140831455993788,\n",
       " 'animals': 0.5048193402825422,\n",
       " 'ankles': 0.2625523103334144,\n",
       " 'ann': -0.25605507605024885,\n",
       " 'anne': 0.301404765055295,\n",
       " 'annexe': -0.19845582705323628,\n",
       " 'anni': 0.12333407345490363,\n",
       " 'annie': 0.15987720475716224,\n",
       " 'annihilate': 0.7204682536756691,\n",
       " 'annihilated': -0.3431250024153846,\n",
       " 'annilihate': -0.09911776272935983,\n",
       " 'announced': -0.14383528179036478,\n",
       " 'announcement': 0.045870187765290234,\n",
       " 'announcements': -0.12375192217121692,\n",
       " 'announcer': -0.15085071079869028,\n",
       " 'announcing': 0.05850408246418523,\n",
       " 'annoy': -0.18918425931215385,\n",
       " 'annoying': 0.7908600298455634,\n",
       " 'anomalies': -0.2510024334940909,\n",
       " 'anonymous': -1.0959881906281013,\n",
       " 'anorexic': 0.44852528806356184,\n",
       " 'another': -0.08900818439245133,\n",
       " 'answer': -0.7230745489956945,\n",
       " 'answered': -0.37076281761509244,\n",
       " 'answering': 0.3235077485118102,\n",
       " 'answers': 0.5122787838904161,\n",
       " 'ant': 0.5043838253249935,\n",
       " 'antelope': -0.26906048555138357,\n",
       " 'anterior': -0.20085637875267898,\n",
       " 'anthony': -0.29574631457055817,\n",
       " 'anti': -0.7222694389140234,\n",
       " 'antialias': -0.21686310600083494,\n",
       " 'antibumping': -0.09298847216025222,\n",
       " 'antichrist': -0.06876395844134187,\n",
       " 'anticipate': -0.519825090664702,\n",
       " 'anticipation': -0.5213264319879506,\n",
       " 'anticlimactic': -0.27521480955839805,\n",
       " 'antics': -0.2551524273667738,\n",
       " 'antidote': 0.5095927562269021,\n",
       " 'antique': 0.3259406457842488,\n",
       " 'anton': 0.09854149879835032,\n",
       " 'antsy': -0.12590675698526407,\n",
       " 'antwerp': -0.40508775595337637,\n",
       " 'anubis': 0.009828258227234578,\n",
       " 'anunidentified': -0.24762350239171546,\n",
       " 'anus': 0.5111166779409643,\n",
       " 'anvil': -0.07838864297669267,\n",
       " 'anxious': -0.1009709677734014,\n",
       " 'any': -0.024888226356214,\n",
       " 'anybody': -1.046253818660436,\n",
       " 'anyhow': 0.3622898407579189,\n",
       " 'anymore': -0.2691076144762218,\n",
       " 'anyone': 0.5183899111357767,\n",
       " 'anyonewho': -0.4085889405544085,\n",
       " 'anythin': -0.4510562533250274,\n",
       " 'anything': -0.4426981816155864,\n",
       " 'anythingabout': -0.23534477474624468,\n",
       " 'anytime': -0.4797148176606705,\n",
       " 'anyway': -0.29702316770079173,\n",
       " 'anyways': 0.20235130047609481,\n",
       " 'anywhere': 0.4144811579497614,\n",
       " 'apache': 0.04962915085291707,\n",
       " 'apart': -0.6411374503913401,\n",
       " 'apartment': 0.44239926124928636,\n",
       " 'apartments': -0.06058908969564239,\n",
       " 'apathetically': 0.13174270816559144,\n",
       " 'apathy': -0.21445251336897844,\n",
       " 'ape': -0.43775436964658415,\n",
       " 'apes': -0.6268325377647114,\n",
       " 'apocalypse': 0.0019113833351266372,\n",
       " 'apocalyptic': -0.2267499467850934,\n",
       " 'apokolips': -0.31083199974638936,\n",
       " 'apollo': 0.18175968265558584,\n",
       " 'apologies': -0.23334488485228078,\n",
       " 'apologise': 0.4565221170579211,\n",
       " 'apologize': 0.6537228254843819,\n",
       " 'apologized': 0.5294527827789783,\n",
       " 'apologizes': 0.1475055891588329,\n",
       " 'apology': 0.46067112728086057,\n",
       " 'apophis': 0.19635279489115742,\n",
       " 'apostate': 0.03243439659865705,\n",
       " 'apostles': -0.17119479579437036,\n",
       " 'app': -0.39445812382507006,\n",
       " 'appalled': 0.014322126261910319,\n",
       " 'apparatus': -0.3218897309269338,\n",
       " 'apparently': -0.8128253544436025,\n",
       " 'appeal': -0.37075646982424315,\n",
       " 'appealing': -0.09147760597259462,\n",
       " 'appear': -0.21831924177348275,\n",
       " 'appearance': 0.0453730456328516,\n",
       " 'appeared': -0.3021789091309399,\n",
       " 'appears': -0.7153669172479395,\n",
       " 'appease': 0.17549470581699225,\n",
       " 'appendicitis': -0.21509758230680434,\n",
       " 'appetiser': 0.43442504372902874,\n",
       " 'appetite': -0.16538967672522728,\n",
       " 'appetites': -0.21014219865057357,\n",
       " 'applaud': 0.25469788931403947,\n",
       " 'applauded': -0.49982341598060853,\n",
       " 'apple': 0.109109097658921,\n",
       " 'applebutter': 0.008472173135019093,\n",
       " 'apples': 0.3550415030064797,\n",
       " 'appliances': -0.1612374753335374,\n",
       " 'apply': 0.19243350790079503,\n",
       " 'applying': 0.3717353043770034,\n",
       " 'appointed': -0.3303977874473141,\n",
       " 'appointment': 0.1251872659716054,\n",
       " 'appreciate': -0.9019347418940323,\n",
       " 'apprentice': -0.20607428070170009,\n",
       " 'approach': -0.09638743558980044,\n",
       " 'approaching': -0.10374408390706691,\n",
       " 'appropriate': -0.047384427859305356,\n",
       " 'appropriated': 0.008040829258228922,\n",
       " 'approve': 0.2766686733762848,\n",
       " 'approved': 0.015768693482056673,\n",
       " 'apron': 0.4303507170238914,\n",
       " 'apt': 0.020156195874965678,\n",
       " 'aquarius': -0.3481010258079412,\n",
       " 'aqueduct': -0.2686483615105312,\n",
       " 'aquinas': 0.024372771263571555,\n",
       " 'ar': 0.15864583725239023,\n",
       " 'ar10': -0.02594899723603274,\n",
       " 'arab': 0.36482301179577376,\n",
       " 'arabic': -0.003885495602982155,\n",
       " 'arabs': 0.32343322457977286,\n",
       " 'arachnopest': 0.3078559042891028,\n",
       " 'aramis': -0.18005592603717044,\n",
       " 'arcadian': 0.23371058775694853,\n",
       " 'archaeologists': -0.5367908016306477,\n",
       " 'archeological': -0.2405619835451288,\n",
       " 'archer': -0.22201816788007073,\n",
       " 'archers': 0.0636548455268567,\n",
       " 'archery': -0.32940189282826543,\n",
       " 'arches': -0.12127302027410329,\n",
       " 'archibald': -0.2690324935637986,\n",
       " 'archie': 0.3758909535989813,\n",
       " 'architect': 0.17610920940548508,\n",
       " 'architecturally': 0.23371058775694853,\n",
       " 'are': 0.31889206247339086,\n",
       " 'area': -0.6065911030763138,\n",
       " 'areas': 0.15264679233889047,\n",
       " 'arec': -0.2876843257367079,\n",
       " 'aren': 0.18165820380295014,\n",
       " 'arena': 0.010847350490089626,\n",
       " 'arendish': -0.2233021155440218,\n",
       " 'areyou': -0.3256981385710554,\n",
       " 'argentina': 0.4662532724217639,\n",
       " 'argh': -0.44888596960805355,\n",
       " 'argue': -0.747867225577504,\n",
       " 'argues': 0.060203130014836466,\n",
       " 'arguing': -0.24544676028557796,\n",
       " 'argument': -0.15457811924274817,\n",
       " 'ari': -0.20357335966379803,\n",
       " 'ariadne': -0.2020944967509818,\n",
       " 'arise': -0.11599547709597402,\n",
       " 'arises': -0.022819456551679374,\n",
       " 'arizona': 0.14205239678387296,\n",
       " 'arjun': 0.4500895903060691,\n",
       " 'ark': -0.05414286415034268,\n",
       " 'arkansas': -0.08836766976775522,\n",
       " 'arlen': -0.3520408185122337,\n",
       " 'arlo': 0.0724252106760748,\n",
       " 'arm': -0.288788517201319,\n",
       " 'armaan': 0.6841779486825758,\n",
       " 'armadillo': -0.12270069343693313,\n",
       " 'armageddon': 0.3199775673846927,\n",
       " 'armalite': -0.02594899723603274,\n",
       " 'armand': 0.03686284488362091,\n",
       " 'armed': -0.37721416047370915,\n",
       " 'armenians': 0.4356160697965986,\n",
       " 'armies': 0.00784881332193458,\n",
       " 'armor': -0.7903364631216736,\n",
       " 'armpit': -0.07147102321359894,\n",
       " 'armpits': -0.14151158080235665,\n",
       " 'arms': -0.6167537521537764,\n",
       " 'armstrong': -0.20705903287333866,\n",
       " 'army': 0.005684494880617993,\n",
       " 'arn': -0.23604570776403747,\n",
       " 'arns': -0.21376334723446477,\n",
       " 'arose': 0.0845521264731954,\n",
       " 'around': -0.37222667416857985,\n",
       " 'arounda': -0.13709670922612363,\n",
       " 'aroundto': 0.29615886608068803,\n",
       " 'arouse': 0.3864098164307194,\n",
       " 'aroused': 0.499828827451745,\n",
       " 'arraign': 0.024084396837081832,\n",
       " 'arranged': -0.0834738829721285,\n",
       " 'arrangement': -0.3609792588339421,\n",
       " 'arranging': 0.1685448444092963,\n",
       " 'arras': -0.18629263264770837,\n",
       " 'arrest': 0.3684277496896349,\n",
       " 'arrested': -0.4599860821136127,\n",
       " 'arresting': 0.010747670949087343,\n",
       " 'arrival': 0.04850601833746213,\n",
       " 'arrive': -0.3620465832601289,\n",
       " 'arrived': -0.034317771452048826,\n",
       " 'arrogance': 0.1422596221640962,\n",
       " 'arrogant': 0.7552535107806159,\n",
       " 'arrow': 0.013059311043868732,\n",
       " 'arse': 2.1754830055561705,\n",
       " 'arsehole': 0.73193160102708,\n",
       " 'arseholes': 0.21393268727889714,\n",
       " 'arsenal': 0.10872035105225662,\n",
       " 'art': -0.40116628508104996,\n",
       " 'artery': -0.27692856031260615,\n",
       " 'arthritic': 0.4378765515358599,\n",
       " 'arthur': 0.528974389977882,\n",
       " 'article': -0.0315184145929987,\n",
       " 'articulate': -0.377970077704065,\n",
       " 'artie': 0.6440467196605306,\n",
       " 'artifact': 0.08088409218414502,\n",
       " 'artificially': 0.20896330944891062,\n",
       " 'artillery': 0.44167387817377257,\n",
       " 'artist': 0.5770326173744349,\n",
       " 'artiste': 0.1628150743405378,\n",
       " 'artistic': -0.19977765416913712,\n",
       " 'artists': -0.19977765416913712,\n",
       " 'arts': 0.029179600144114904,\n",
       " 'artsy': -0.5370705860347051,\n",
       " 'arturo': 0.048429227044311754,\n",
       " 'as': -0.10592029056302431,\n",
       " 'ascetic': 0.3555438514729656,\n",
       " 'asgardians': 0.5493163856246538,\n",
       " 'ash': 0.36395483287161,\n",
       " 'ashamed': -0.36937186359563895,\n",
       " 'asher': 0.09816828738448756,\n",
       " 'asherah': 0.24671697186099636,\n",
       " 'ashes': -0.08828203588166453,\n",
       " 'ashitaka': -0.17610341119407688,\n",
       " 'ashore': -0.19604912602816493,\n",
       " 'ashram': -0.225262543805026,\n",
       " 'asia': 0.19905153758306263,\n",
       " 'asian': -0.03308667530689469,\n",
       " 'asians': 0.8609611300929548,\n",
       " 'aside': -0.4069288374854166,\n",
       " 'asinine': 0.5653302131889081,\n",
       " 'ask': -0.06586045857596029,\n",
       " 'asked': -0.09130005682674378,\n",
       " 'asking': -0.11702824143177881,\n",
       " 'askingstupid': 0.306081088309928,\n",
       " 'asks': -0.2603408509437456,\n",
       " 'asleep': 0.437846454658993,\n",
       " 'asparagus': -0.09623779730616049,\n",
       " 'aspect': -0.6443396774394491,\n",
       " 'asperger': -0.20811754547784825,\n",
       " 'asphyxiate': -0.17816787061069753,\n",
       " 'asphyxiation': 0.36897986904785635,\n",
       " 'aspire': -0.1807185701869855,\n",
       " 'aspires': 0.45136070545019863,\n",
       " 'ass': 3.9850885482601104,\n",
       " 'assasin': 0.3964300416676957,\n",
       " 'assassin': -1.4149650941294536,\n",
       " 'assassinate': -0.3804457588077123,\n",
       " 'assassinated': -0.015438461316265509,\n",
       " 'assassination': 0.041482069060410215,\n",
       " 'assassins': -0.04211539332190168,\n",
       " 'assault': -0.41425566117070384,\n",
       " 'assaulted': 0.8662937471749991,\n",
       " 'assed': -0.32965230442076754,\n",
       " 'assegai': -0.11342290008679855,\n",
       " 'assemble': 0.07694144968720469,\n",
       " 'assembled': -0.06837893723140674,\n",
       " 'asses': 2.5402232790451107,\n",
       " 'assessment': -0.3043061646603007,\n",
       " 'asset': -0.28394525575767837,\n",
       " 'assho': 0.007125635184952618,\n",
       " 'asshole': 3.136900737663769,\n",
       " 'assholes': 1.3041084376491276,\n",
       " 'assian': -0.10623791457261288,\n",
       " 'assigned': -0.15463769503656552,\n",
       " 'assignment': -0.9863545405883615,\n",
       " 'assistant': 0.6981617177342052,\n",
       " 'associate': 0.20763951631852393,\n",
       " 'associates': 0.06566776489261222,\n",
       " 'associating': 0.03238974985144484,\n",
       " 'association': -0.6353391897893216,\n",
       " 'associations': -0.3118300577600009,\n",
       " 'assortment': -0.17057717180664747,\n",
       " 'assume': 0.2968239689416653,\n",
       " 'assumed': 0.3962808867084392,\n",
       " 'assuming': -0.13399645703211974,\n",
       " 'assumption': -0.2840645710044029,\n",
       " 'assure': -0.2772675590872113,\n",
       " 'assured': -0.24046803293102248,\n",
       " 'assyrians': 0.5441324102134143,\n",
       " 'astaire': -0.46051705812374993,\n",
       " 'astonishingly': 0.08376869648538744,\n",
       " 'astor': -0.10998276428926212,\n",
       " 'astraddle': 0.19751411376639266,\n",
       " 'astray': -0.20774966992349658,\n",
       " 'astrology': 0.07479609182299832,\n",
       " 'astupid': 0.4531539152776318,\n",
       " 'asty': 0.2401996390672871,\n",
       " 'asuka': 0.03731265526466444,\n",
       " 'asylum': -0.2662525085808196,\n",
       " 'at': 0.16622169661338154,\n",
       " 'ate': -0.1670125730341531,\n",
       " 'athlete': 0.021438236577807777,\n",
       " 'athletic': 0.0041250201759503715,\n",
       " 'atiaran': 0.24876294955015,\n",
       " 'atlantic': 0.25785847626989844,\n",
       " 'atlasow': -0.3317786629677191,\n",
       " 'atm': -0.21301663101130178,\n",
       " 'atomic': -0.239474373424819,\n",
       " 'atone': -0.08277371163887054,\n",
       " 'atrocitus': 0.3752983266706642,\n",
       " 'atropa': -0.14824053428852887,\n",
       " 'attached': 0.10523798096487078,\n",
       " 'attachment': -0.09502834867197538,\n",
       " 'attack': 0.268539341401345,\n",
       " 'attacked': -0.3745822767625623,\n",
       " 'attacker': 0.3217285382217283,\n",
       " 'attacking': -0.3680097377156213,\n",
       " 'attacks': -0.09009926640044795,\n",
       " 'attagirls': -0.31608269646663145,\n",
       " 'attempt': -0.31728862935133,\n",
       " 'attempted': -0.4390456792825182,\n",
       " 'attempting': -0.2267499467850934,\n",
       " 'attempts': -0.217185681563675,\n",
       " 'attending': 0.20691378208458505,\n",
       " 'attention': -0.3203406391898438,\n",
       " 'attentions': -0.26505887799858885,\n",
       " 'attic': 0.8494496075307415,\n",
       " 'attitude': -0.19435545733686166,\n",
       " 'attitudes': -0.2466003906757562,\n",
       " 'attorney': -0.9244739479886915,\n",
       " 'attract': 0.3500945852630464,\n",
       " 'attracted': 0.21669362557380506,\n",
       " 'attraction': -0.4996030453840462,\n",
       " 'attractive': 0.5417994694351328,\n",
       " 'attracts': -0.2482484414651356,\n",
       " 'auction': -0.43666004803627545,\n",
       " 'audible': 0.260047553431926,\n",
       " 'audigier': 0.004351752397226921,\n",
       " 'audrey': 0.012610725118711905,\n",
       " 'auerbach': 0.0628862127386253,\n",
       " 'aught': -0.12791315146661628,\n",
       " 'augment': 0.0997364990267521,\n",
       " 'augury': -0.20729196464077257,\n",
       " 'august': 0.040389071853248214,\n",
       " 'aunt': 0.5962072939677772,\n",
       " 'aunts': 0.04829224350669718,\n",
       " 'auschwitz': 0.01667944235209383,\n",
       " 'austerity': -0.17846865060440165,\n",
       " 'australia': 0.4854884962443424,\n",
       " 'australian': -0.20482963941445598,\n",
       " 'australians': -0.10229915885863819,\n",
       " 'authority': -0.03726287858488633,\n",
       " 'auto': 0.754404412477291,\n",
       " 'automatic': 0.443687652693045,\n",
       " 'automobiles': 0.15216825494234257,\n",
       " 'autopsy': 0.4744607959264089,\n",
       " 'auxiliary': -0.09557162870682073,\n",
       " 'ava': 0.07751323534733519,\n",
       " 'avalon': -0.1818009704845163,\n",
       " 'avatar': 0.06672997067303575,\n",
       " 'avenge': 0.6020404043223774,\n",
       " 'avenged': -0.054379114343367785,\n",
       " 'avenue': -0.038000989123220155,\n",
       " 'average': 0.13138989631887446,\n",
       " 'avner': -0.2664589883468952,\n",
       " 'avoid': -0.4765748109084314,\n",
       " 'avoided': 0.16280160080373884,\n",
       " 'avoiding': 0.026615906274113036,\n",
       " 'avon': 0.029072105297444355,\n",
       " 'aw': -0.9227999168484815,\n",
       " 'awaiting': 0.28043087526926747,\n",
       " 'awaits': 0.3902501072281985,\n",
       " 'awake': -0.1610551671005412,\n",
       " 'awakened': -0.30937382871262314,\n",
       " 'awakening': -0.23712584687495245,\n",
       " 'award': -0.23919270718889218,\n",
       " 'awarded': -0.04870591284071139,\n",
       " 'awards': -0.3838754547120682,\n",
       " 'aware': -0.09929074739698286,\n",
       " 'away': -0.3693449924913709,\n",
       " 'awesome': -1.1488245721450039,\n",
       " 'awful': 0.3773445416818128,\n",
       " 'awfully': -0.2297621596179948,\n",
       " 'awhile': -0.16251914590195557,\n",
       " 'awkward': 0.38445493955486226,\n",
       " 'awol': 0.1656505921526042,\n",
       " 'aww': -0.5684000214321251,\n",
       " 'ax': -0.2978993359144015,\n",
       " 'axe': -0.8300597559791564,\n",
       " 'axes': -0.28153607600131986,\n",
       " 'axis': 0.3933590924264003,\n",
       " 'axl': -0.514539766385596,\n",
       " 'ay': 0.2806671281664366,\n",
       " 'aye': 0.04269801912853684,\n",
       " 'ayush': -0.23326782986957928,\n",
       " 'azog': -0.1824709995078368,\n",
       " 'baalites': 0.1398629932402099,\n",
       " 'babe': -0.6423992904828476,\n",
       " 'babies': 0.22163840370869078,\n",
       " 'baboon': -0.2788512172949766,\n",
       " 'babs': 0.6409264167079981,\n",
       " 'baby': 0.45455319546576184,\n",
       " 'babylon': 0.08051387996231717,\n",
       " 'babylons': -0.2569369017663113,\n",
       " 'babysit': 0.45042576749872026,\n",
       " 'babysitters': 0.4301794721292252,\n",
       " 'babysitting': 0.4301794721292252,\n",
       " 'bacharach': -0.13085401865701493,\n",
       " 'bachelor': -0.023703236152332916,\n",
       " 'bacillus': 0.3526552161983273,\n",
       " 'back': -0.076156489875327,\n",
       " 'backache': 0.277429197352591,\n",
       " 'backbone': -0.0708439123922507,\n",
       " 'backbut': 0.0017773948543599548,\n",
       " 'backed': 0.21948067246474492,\n",
       " 'backfire': -0.21820762965298635,\n",
       " 'background': -0.8917786191238516,\n",
       " 'backhanded': -0.5093046080491432,\n",
       " 'backin': 0.2567468271726297,\n",
       " 'backing': -0.09204515504335087,\n",
       " 'backpack': 0.0037145630190054154,\n",
       " 'backs': -0.015470063566159846,\n",
       " 'backseat': -0.47249231548119314,\n",
       " 'backside': 0.5612001359723227,\n",
       " 'backsides': -0.10368537636084273,\n",
       " 'backssmeared': -0.29126087141600643,\n",
       " 'backstabbing': -0.17660603113306342,\n",
       " 'backup': -0.170128404893527,\n",
       " 'backward': 1.833673647266714e-05,\n",
       " 'backwards': 0.002527885327206107,\n",
       " 'backwaters': 0.37606268113520985,\n",
       " 'backyard': -0.3012233477425564,\n",
       " 'bacon': -0.14835079683820268,\n",
       " 'bad': -0.19145252796863246,\n",
       " 'badass': -0.1547767215988667,\n",
       " 'badasses': 0.11230566317884846,\n",
       " 'baddest': 0.00899981932363156,\n",
       " 'badge': 0.12723056883708758,\n",
       " 'badger': -0.28241965117642837,\n",
       " 'badgers': 0.02714783260203006,\n",
       " 'badly': -0.5732333796909989,\n",
       " 'badonkadonk': -0.11504006241839161,\n",
       " 'baek': -0.39474027858225813,\n",
       " ...}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_toxicity_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['waste',\n",
       " 'nasty',\n",
       " 'spare',\n",
       " 'your',\n",
       " 'put',\n",
       " 'her',\n",
       " 'die',\n",
       " 'ass',\n",
       " 'black',\n",
       " 'hell',\n",
       " 'crap',\n",
       " 'want',\n",
       " 'sweet',\n",
       " 'kill',\n",
       " 'him',\n",
       " 'shit',\n",
       " 'dog',\n",
       " 'die',\n",
       " 'die',\n",
       " 'whatever',\n",
       " 'kill',\n",
       " 'fuck',\n",
       " 'are',\n",
       " 'met',\n",
       " 'crazy',\n",
       " 'shit',\n",
       " 'fucking',\n",
       " 'porn',\n",
       " 'porn',\n",
       " 'bastard',\n",
       " 'want',\n",
       " 'punching',\n",
       " 'butt',\n",
       " 'shit',\n",
       " 'front',\n",
       " 'him',\n",
       " 'killer',\n",
       " 'kill',\n",
       " 'morals',\n",
       " 'integrity',\n",
       " 'killing',\n",
       " 'savage',\n",
       " 'fucking',\n",
       " 'killer',\n",
       " 'bitch',\n",
       " 'your',\n",
       " 'happens',\n",
       " 'bored',\n",
       " 'witless',\n",
       " 'work',\n",
       " 'these',\n",
       " 'irresponsible',\n",
       " 'how',\n",
       " 'are',\n",
       " 'die',\n",
       " 'twisted',\n",
       " 'dopey',\n",
       " 'kill',\n",
       " 'smelling',\n",
       " 'she',\n",
       " 'anal',\n",
       " 'nuts',\n",
       " 'burn',\n",
       " 'girlfriends',\n",
       " 'are',\n",
       " 'dead',\n",
       " 'bastard',\n",
       " 'braver',\n",
       " 'foolhardy',\n",
       " 'hell',\n",
       " 'nolan',\n",
       " 'crap',\n",
       " 'hope',\n",
       " 'your',\n",
       " 'pee',\n",
       " 'pee',\n",
       " 'send',\n",
       " 'sex',\n",
       " 'shit',\n",
       " 'damn',\n",
       " 'bloody',\n",
       " 'rotten',\n",
       " 'hell',\n",
       " 'your',\n",
       " 'womanizing',\n",
       " 'your',\n",
       " 'college',\n",
       " 'dead',\n",
       " 'fight',\n",
       " 'want',\n",
       " 'clearly',\n",
       " 'crybaby',\n",
       " 'niggers',\n",
       " 'shit',\n",
       " 'filthy',\n",
       " 'fucking',\n",
       " 'kill',\n",
       " 'ass',\n",
       " 'whore',\n",
       " 'kill',\n",
       " 'motherfucker',\n",
       " 'happen',\n",
       " 'fucking',\n",
       " 'monkey',\n",
       " 'arrogant',\n",
       " 'should',\n",
       " 'crummy',\n",
       " 'cashier',\n",
       " 'fuck',\n",
       " 'rape',\n",
       " 'an',\n",
       " 'she',\n",
       " 'off',\n",
       " 'her',\n",
       " 'she',\n",
       " 'glad',\n",
       " 'kill',\n",
       " 'fucked',\n",
       " 'bloody',\n",
       " 'awful',\n",
       " 'these',\n",
       " 'glasses',\n",
       " 'come',\n",
       " 'bonsal',\n",
       " 'attack',\n",
       " 'visitors',\n",
       " 'him',\n",
       " 'jerk',\n",
       " 'killing',\n",
       " 'fool',\n",
       " 'off',\n",
       " 'die',\n",
       " 'your',\n",
       " 'tit',\n",
       " 'caught',\n",
       " 'ringer',\n",
       " 'shut',\n",
       " 'human',\n",
       " 'camp',\n",
       " 'starve',\n",
       " 'fucking',\n",
       " 'him',\n",
       " 'fear',\n",
       " 'hit',\n",
       " 'should',\n",
       " 'brains',\n",
       " 'jailfor',\n",
       " 'going',\n",
       " 'anywhere',\n",
       " 'with',\n",
       " 'minds',\n",
       " 'kill',\n",
       " 'make',\n",
       " 'going',\n",
       " 'killing',\n",
       " 'fat',\n",
       " 'wife',\n",
       " 'with',\n",
       " 'are',\n",
       " 'villains',\n",
       " 'are',\n",
       " 'myself',\n",
       " 'die',\n",
       " 'car',\n",
       " 'loser',\n",
       " 'goddamn',\n",
       " 'rubbish',\n",
       " 'shot',\n",
       " '45',\n",
       " 'fuck',\n",
       " 'shot',\n",
       " 'hand',\n",
       " 'self',\n",
       " 'fuckin',\n",
       " 'goddamn',\n",
       " 'fucked',\n",
       " 'asshole',\n",
       " 'never',\n",
       " 'full',\n",
       " 'stayed',\n",
       " 'hit',\n",
       " 'con',\n",
       " 'stealing',\n",
       " 'from',\n",
       " 'wealthy',\n",
       " 'pull',\n",
       " 'bleed',\n",
       " 'dead',\n",
       " 'cold',\n",
       " 'sex',\n",
       " 'behave',\n",
       " 'off',\n",
       " 'animal',\n",
       " 'fucking',\n",
       " 'assaulted',\n",
       " 'monster',\n",
       " 'burned',\n",
       " 'license',\n",
       " 'client',\n",
       " 'gay',\n",
       " 'cunt',\n",
       " 'your',\n",
       " 'wetness',\n",
       " 'them',\n",
       " 'gonna',\n",
       " 'whup',\n",
       " 'yours',\n",
       " 'wake',\n",
       " 'dead',\n",
       " 'bugger',\n",
       " 'speak',\n",
       " 'want',\n",
       " 'dead',\n",
       " 'dead',\n",
       " 'say',\n",
       " 'fucking',\n",
       " 'hooker',\n",
       " 'idiot',\n",
       " 'ass',\n",
       " 'want',\n",
       " 'want',\n",
       " 'mental',\n",
       " 'her',\n",
       " 'gun',\n",
       " 'pencil',\n",
       " 'fuckin',\n",
       " 'miserable',\n",
       " 'shoot',\n",
       " 'your',\n",
       " 'fuck',\n",
       " 'stupid',\n",
       " 'are',\n",
       " 'kill',\n",
       " 'kill',\n",
       " 'kill',\n",
       " 'silly',\n",
       " 'shit',\n",
       " 'gay',\n",
       " 'bunch',\n",
       " 'dead',\n",
       " 'girls',\n",
       " 'lesbians',\n",
       " 'bloody',\n",
       " 'fade',\n",
       " 'wrap',\n",
       " 'decided',\n",
       " 'rat',\n",
       " 'gonna',\n",
       " 'make',\n",
       " 'years',\n",
       " 'shot',\n",
       " 'animal',\n",
       " 'myself',\n",
       " 'sewer',\n",
       " 'horrible',\n",
       " 'such',\n",
       " 'rehearsal',\n",
       " 'powerful',\n",
       " 'powerful',\n",
       " 'orgasm',\n",
       " 'secret',\n",
       " 'skin',\n",
       " 'gonna',\n",
       " 'attack',\n",
       " 'her',\n",
       " 'shit',\n",
       " 'black',\n",
       " 'overwhelmed',\n",
       " 'ridiculousness',\n",
       " 'fuck',\n",
       " 'wife',\n",
       " 'asshole',\n",
       " 'march',\n",
       " 'trample',\n",
       " 'into',\n",
       " 'horrid',\n",
       " 'face',\n",
       " 'sick',\n",
       " 'sucking',\n",
       " 'insults',\n",
       " 'shake',\n",
       " 'trash',\n",
       " 'bullshit',\n",
       " 'selfish',\n",
       " 'bastard',\n",
       " 'girl',\n",
       " 'wife',\n",
       " 'weeks',\n",
       " 'bipolar',\n",
       " 'mutilate',\n",
       " 'under',\n",
       " 'your',\n",
       " 'crappy',\n",
       " 'hang',\n",
       " 'crap',\n",
       " 'shit',\n",
       " 'want',\n",
       " 'face',\n",
       " 'deserve',\n",
       " 'cut',\n",
       " 'food',\n",
       " 'fuck',\n",
       " 'baseman',\n",
       " 'fucking',\n",
       " 'are',\n",
       " 'gut',\n",
       " 'drink',\n",
       " 'station',\n",
       " 'girl',\n",
       " 'skin',\n",
       " 'kid',\n",
       " 'sister',\n",
       " 'ejaculated',\n",
       " 'lowlifes',\n",
       " 'are',\n",
       " 'animals',\n",
       " 'fought',\n",
       " 'men',\n",
       " 'are',\n",
       " 'killed',\n",
       " 'junk',\n",
       " 'bury',\n",
       " 'dead',\n",
       " 'country',\n",
       " 'killing',\n",
       " 'butt',\n",
       " 'sucks',\n",
       " 'shit',\n",
       " 'foul',\n",
       " 'killed',\n",
       " 'her',\n",
       " 'throats',\n",
       " 'sooner',\n",
       " 'fat',\n",
       " 'pig',\n",
       " 'him',\n",
       " 'him',\n",
       " 'bitch',\n",
       " 'gonna',\n",
       " 'suck',\n",
       " 'cock',\n",
       " 'wife',\n",
       " 'yes',\n",
       " 'excitement',\n",
       " 'from',\n",
       " 'your',\n",
       " 'turns',\n",
       " 'girl',\n",
       " 'killed',\n",
       " 'are',\n",
       " 'come',\n",
       " 'friggin',\n",
       " 'mural',\n",
       " 'museum',\n",
       " 'hell',\n",
       " 'them',\n",
       " 'shit',\n",
       " 'gonna',\n",
       " 'save',\n",
       " 'them',\n",
       " 'shoot',\n",
       " 'violence',\n",
       " 'human',\n",
       " 'crazy',\n",
       " 'cowards',\n",
       " 'him',\n",
       " 'him',\n",
       " 'genocide',\n",
       " 'damned',\n",
       " 'sick',\n",
       " 'such',\n",
       " 'those',\n",
       " 'from',\n",
       " 'should',\n",
       " 'win',\n",
       " 'wife',\n",
       " 'shitty',\n",
       " 'kid',\n",
       " 'your',\n",
       " 'shit',\n",
       " 'slut',\n",
       " 'suck',\n",
       " 'poor',\n",
       " 'shit',\n",
       " 'ass',\n",
       " 'your',\n",
       " 'jizz',\n",
       " 'kill',\n",
       " 'rights',\n",
       " 'silly',\n",
       " 'mental',\n",
       " 'justcall',\n",
       " 'him',\n",
       " 'pile',\n",
       " 'fucking',\n",
       " 'pooed',\n",
       " 'kill',\n",
       " 'american',\n",
       " 'killed',\n",
       " 'asshole',\n",
       " 'with',\n",
       " 'these',\n",
       " 'your',\n",
       " 'mouth',\n",
       " 'treat',\n",
       " 'are',\n",
       " 'erotic',\n",
       " 'most',\n",
       " 'deranged',\n",
       " 'damn',\n",
       " 'ridiculous',\n",
       " 'dead',\n",
       " 'put',\n",
       " 'bullet',\n",
       " 'car',\n",
       " 'gangster',\n",
       " 'questions',\n",
       " 'with',\n",
       " 'an',\n",
       " 'irrational',\n",
       " 'vicious',\n",
       " 'bloody',\n",
       " '20',\n",
       " 'gonna',\n",
       " 'garbage',\n",
       " 'upstairs',\n",
       " 'bitch',\n",
       " 'shit',\n",
       " 'finish',\n",
       " 'her',\n",
       " 'off',\n",
       " 'damn',\n",
       " 'only',\n",
       " 'these',\n",
       " 'jerk',\n",
       " 'thief',\n",
       " 'them',\n",
       " 'her',\n",
       " 'from',\n",
       " 'behind',\n",
       " 'shits',\n",
       " 'ridiculous',\n",
       " 'ordering',\n",
       " 'strike',\n",
       " 'bastard',\n",
       " 'fuck',\n",
       " 'stupid',\n",
       " 'dump',\n",
       " 'silly',\n",
       " 'serving',\n",
       " 'bloody',\n",
       " 'goddamn',\n",
       " 'useless',\n",
       " 'asshole',\n",
       " 'suck',\n",
       " 'dead',\n",
       " 'disgusting',\n",
       " 'difference',\n",
       " 'killed',\n",
       " 'else',\n",
       " 'idiots',\n",
       " 'with',\n",
       " 'foul',\n",
       " 'your',\n",
       " 'dead',\n",
       " 'punching',\n",
       " 'mental',\n",
       " 'are',\n",
       " 'going',\n",
       " 'miscreants',\n",
       " 'jerk',\n",
       " 'nonsense',\n",
       " 'punch',\n",
       " 'front',\n",
       " 'beneath',\n",
       " 'buttocks',\n",
       " 'yes',\n",
       " 'an',\n",
       " 'ridiculous',\n",
       " 'goddamn',\n",
       " 'survive',\n",
       " 'kills',\n",
       " 'goofy',\n",
       " 'executioner',\n",
       " 'victim',\n",
       " 'are',\n",
       " 'fucking',\n",
       " 'kill',\n",
       " 'piss',\n",
       " 'wooden',\n",
       " 'her',\n",
       " 'shit',\n",
       " 'bloody',\n",
       " 'em',\n",
       " 'dead',\n",
       " 'ass',\n",
       " 'her',\n",
       " 'sbeen',\n",
       " 'filth',\n",
       " 'bullet',\n",
       " 'woman',\n",
       " 'shit',\n",
       " 'him',\n",
       " 'him',\n",
       " 'fuck',\n",
       " 'blasted',\n",
       " 'rubbish',\n",
       " 'shoot',\n",
       " 'your',\n",
       " 'father',\n",
       " 'still',\n",
       " 'with',\n",
       " 'cellar',\n",
       " 'reeks',\n",
       " 'dog',\n",
       " 'shot',\n",
       " 'whatever',\n",
       " 'rat',\n",
       " 'brain',\n",
       " 'shoot',\n",
       " 'damn',\n",
       " 'sex',\n",
       " 'crazy',\n",
       " 'fucking',\n",
       " 'dead',\n",
       " 'killed',\n",
       " 'hell',\n",
       " 'crap',\n",
       " 'crazy',\n",
       " 'screwing',\n",
       " 'stupid',\n",
       " 'killed',\n",
       " 'father',\n",
       " 'junk',\n",
       " 'sex',\n",
       " 'shot',\n",
       " 'fucking',\n",
       " 'motherfucker',\n",
       " 'cold',\n",
       " 'crazy',\n",
       " 'shot',\n",
       " 'knock',\n",
       " 'snake',\n",
       " 'demon',\n",
       " 'screwed',\n",
       " 'guts',\n",
       " 'soap',\n",
       " 'crap',\n",
       " 'black',\n",
       " 'black',\n",
       " 'girl',\n",
       " 'crazy',\n",
       " 'going',\n",
       " 'an',\n",
       " 'kneecaps',\n",
       " 'exploiting',\n",
       " 'abused',\n",
       " 'woman',\n",
       " 'your',\n",
       " 'slaughtered',\n",
       " 'ox',\n",
       " 'insane',\n",
       " 'him',\n",
       " 'naked',\n",
       " 'dirty',\n",
       " 'rotten',\n",
       " 'demon',\n",
       " 'burning',\n",
       " 'kill',\n",
       " 'damned',\n",
       " 'dirty',\n",
       " 'pussycat',\n",
       " 'myself',\n",
       " 'butt',\n",
       " 'never',\n",
       " 'despair',\n",
       " 'despair',\n",
       " 'desecrate',\n",
       " 'fuck',\n",
       " 'useless',\n",
       " 'live',\n",
       " 'fucking',\n",
       " 'finds',\n",
       " 'piss',\n",
       " 'crazy',\n",
       " 'nuts',\n",
       " 'joke',\n",
       " 'cut',\n",
       " 'say',\n",
       " 'damn',\n",
       " 'are',\n",
       " 'lies',\n",
       " 'hypocrisy',\n",
       " 'your',\n",
       " 'stupid',\n",
       " 'women',\n",
       " 'legs',\n",
       " 'stinks',\n",
       " 'shut',\n",
       " 'crushed',\n",
       " 'liar',\n",
       " 'kill',\n",
       " 'how',\n",
       " 'your',\n",
       " 'crimes',\n",
       " 'only',\n",
       " 'with',\n",
       " 'most',\n",
       " 'vile',\n",
       " 'lies',\n",
       " 'him',\n",
       " 'ass',\n",
       " 'crazy',\n",
       " 'fucking',\n",
       " 'shit',\n",
       " 'say',\n",
       " 'your',\n",
       " 'dick',\n",
       " 'are',\n",
       " 'savages',\n",
       " 'animals',\n",
       " 'jump',\n",
       " 'aboard',\n",
       " 'are',\n",
       " 'practically',\n",
       " 'shit',\n",
       " 'your',\n",
       " 'face',\n",
       " 'somebody',\n",
       " 'fuckin',\n",
       " 'fuck',\n",
       " 'sister',\n",
       " 'patience',\n",
       " 'going',\n",
       " 'il',\n",
       " 'bunch',\n",
       " 'white',\n",
       " 'fucking',\n",
       " 'medal',\n",
       " 'dead',\n",
       " 'fat',\n",
       " 'death',\n",
       " 'from',\n",
       " 'your',\n",
       " 'tops',\n",
       " 'hate',\n",
       " 'gun',\n",
       " 'hell',\n",
       " 'hooker',\n",
       " 'crazy',\n",
       " '20',\n",
       " 'years',\n",
       " 'without',\n",
       " 'evil',\n",
       " 'them',\n",
       " 'hit',\n",
       " 'drunk',\n",
       " 'gay',\n",
       " 'want',\n",
       " 'dead',\n",
       " 'hot',\n",
       " 'dog',\n",
       " 'nipple',\n",
       " 'with',\n",
       " 'burn',\n",
       " 'hell',\n",
       " 'monkey',\n",
       " 'mediocre',\n",
       " 'doddering',\n",
       " 'years',\n",
       " 'him',\n",
       " 'alive',\n",
       " 'shit',\n",
       " 'kill',\n",
       " 'with',\n",
       " 'crap',\n",
       " 'fucking',\n",
       " 'gay',\n",
       " 'gay',\n",
       " 'silly',\n",
       " 'put',\n",
       " 'fuck',\n",
       " 'sex',\n",
       " 'fat',\n",
       " 'year',\n",
       " 'knee',\n",
       " 'monster',\n",
       " 'sharply',\n",
       " 'freakin',\n",
       " 'shit',\n",
       " 'gay',\n",
       " 'missing',\n",
       " 'insult',\n",
       " 'fucking',\n",
       " 'fucking',\n",
       " 'hell',\n",
       " 'shit',\n",
       " 'bitch',\n",
       " 'prick',\n",
       " 'worked',\n",
       " 'years',\n",
       " 'bite',\n",
       " 'she',\n",
       " 'fucking',\n",
       " 'garbage',\n",
       " 'starve',\n",
       " 'worried',\n",
       " 'cut',\n",
       " 'wrists',\n",
       " 'hell',\n",
       " 'fucking',\n",
       " 'full',\n",
       " 'pussies',\n",
       " 'piss',\n",
       " 'are',\n",
       " 'die',\n",
       " 'hell',\n",
       " 'dumb',\n",
       " 'ass',\n",
       " 'bitch',\n",
       " 'fucking',\n",
       " 'her',\n",
       " 'she',\n",
       " 'bastard',\n",
       " 'too',\n",
       " 'your',\n",
       " 'hell',\n",
       " 'bother',\n",
       " 'your',\n",
       " 'your',\n",
       " 'your',\n",
       " 'car',\n",
       " 'gonna',\n",
       " 'balls',\n",
       " 'stupid',\n",
       " 'nuts',\n",
       " 'hell',\n",
       " 'sex',\n",
       " 'ridiculous',\n",
       " 'with',\n",
       " 'jerk',\n",
       " 'cop',\n",
       " 'killed',\n",
       " 'going',\n",
       " 'piss',\n",
       " 'baby',\n",
       " 'shoot',\n",
       " 'dead',\n",
       " 'kick',\n",
       " 'blood',\n",
       " 'shit',\n",
       " 'pervert',\n",
       " 'witch',\n",
       " 'fuckin',\n",
       " 'fuck',\n",
       " 'fuckin',\n",
       " 'dick',\n",
       " 'an',\n",
       " 'death',\n",
       " 'prostitute',\n",
       " 'sex',\n",
       " 'sex',\n",
       " 'are',\n",
       " 'grow',\n",
       " 'her',\n",
       " 'her',\n",
       " 'housecoat',\n",
       " 'care',\n",
       " 'her',\n",
       " 'fuck',\n",
       " 'hit',\n",
       " 'kill',\n",
       " 'sister',\n",
       " 'girlfriend',\n",
       " 'fucking',\n",
       " 'hell',\n",
       " 'useless',\n",
       " 'want',\n",
       " 'him',\n",
       " 'fucking',\n",
       " 'means',\n",
       " 'disorder',\n",
       " 'skin',\n",
       " 'elbow',\n",
       " 'dead',\n",
       " 'shit',\n",
       " 'fuck',\n",
       " 'sight',\n",
       " 'shot',\n",
       " 'damn',\n",
       " 'fucking',\n",
       " 'maniac',\n",
       " 'traitor',\n",
       " 'damn',\n",
       " 'want',\n",
       " 'mama',\n",
       " 'want',\n",
       " 'your',\n",
       " 'him',\n",
       " 'gonna',\n",
       " 'till',\n",
       " 'suck',\n",
       " 'sick',\n",
       " 'baby',\n",
       " 'slap',\n",
       " 'your',\n",
       " 'fatsteps',\n",
       " 'those',\n",
       " 'goddamn',\n",
       " 'only',\n",
       " 'her',\n",
       " 'traitor',\n",
       " 'parasites',\n",
       " 'cabin',\n",
       " 'sick',\n",
       " 'with',\n",
       " 'bitches',\n",
       " 'goddamn',\n",
       " 'slaughter',\n",
       " 'until',\n",
       " 'dead',\n",
       " 'shit',\n",
       " 'nasty',\n",
       " 'hell',\n",
       " 'kill',\n",
       " 'black',\n",
       " 'magic',\n",
       " 'screwing',\n",
       " 'ghost',\n",
       " 'sex',\n",
       " 'sex',\n",
       " 'your',\n",
       " 'goddam',\n",
       " 'off',\n",
       " 'she',\n",
       " 'damn',\n",
       " 'pointed',\n",
       " 'incompetent',\n",
       " 'gay',\n",
       " 'punishment',\n",
       " 'crematorium',\n",
       " 'want',\n",
       " 'girls',\n",
       " 'hell',\n",
       " 'minded',\n",
       " 'full',\n",
       " 'yes',\n",
       " 'seems',\n",
       " 'an',\n",
       " 'she',\n",
       " 'your',\n",
       " 'fuck',\n",
       " 'kill',\n",
       " 'guts',\n",
       " 'crazy',\n",
       " 'she',\n",
       " 'drink',\n",
       " 'she',\n",
       " 'shit',\n",
       " 'wusses',\n",
       " 'fuck',\n",
       " 'those',\n",
       " 'are',\n",
       " 'slime',\n",
       " 'himself',\n",
       " 'death',\n",
       " 'him',\n",
       " 'dead',\n",
       " 'uncool',\n",
       " 'kill',\n",
       " 'punishment',\n",
       " 'ass',\n",
       " 'ship',\n",
       " 'throw',\n",
       " 'your',\n",
       " 'your',\n",
       " 'neck',\n",
       " 'fucking',\n",
       " 'sick',\n",
       " 'himself',\n",
       " 'her',\n",
       " 'fucked',\n",
       " 'fuck',\n",
       " 'hell',\n",
       " 'stairs',\n",
       " 'brain',\n",
       " 'shut',\n",
       " 'stealing',\n",
       " 'dead',\n",
       " 'phone',\n",
       " 'off',\n",
       " 'lieutenant',\n",
       " 'beak',\n",
       " 'years',\n",
       " 'intelligent',\n",
       " 'damn',\n",
       " 'boobs',\n",
       " 'damn',\n",
       " 'balls',\n",
       " 'confessed',\n",
       " 'murderer',\n",
       " 'ass',\n",
       " 'hell',\n",
       " 'except',\n",
       " 'yourself',\n",
       " 'killed',\n",
       " 'checked',\n",
       " 'gonna',\n",
       " 'blow',\n",
       " 'shitty',\n",
       " 'hell',\n",
       " 'fucking',\n",
       " 'phone',\n",
       " 'slaughter',\n",
       " 'hurrah',\n",
       " 'hurrah',\n",
       " 'cripple',\n",
       " 'your',\n",
       " 'still',\n",
       " 'fuck',\n",
       " 'asinine',\n",
       " 'are',\n",
       " 'serving',\n",
       " 'il',\n",
       " 'blow',\n",
       " 'car',\n",
       " 'pieces',\n",
       " 'die',\n",
       " 'killing',\n",
       " 'store',\n",
       " 'shit',\n",
       " 'woman',\n",
       " 'should',\n",
       " 'death',\n",
       " 'killing',\n",
       " 'kill',\n",
       " 'stupid',\n",
       " 'sucking',\n",
       " 'hell',\n",
       " 'murderer',\n",
       " 'blow',\n",
       " 'kill',\n",
       " 'them',\n",
       " 'unfortunate',\n",
       " 'death',\n",
       " 'pretentious',\n",
       " 'dink',\n",
       " 'hell',\n",
       " 'sissies',\n",
       " 'with',\n",
       " 'death',\n",
       " 'killing',\n",
       " 'most',\n",
       " 'say',\n",
       " 'damn',\n",
       " 'black',\n",
       " 'killed',\n",
       " 'whatever',\n",
       " 'prick',\n",
       " 'command',\n",
       " 'kid',\n",
       " 'spank',\n",
       " 'wrap',\n",
       " 'make',\n",
       " 'your',\n",
       " 'screw',\n",
       " 'balls',\n",
       " 'your',\n",
       " 'repent',\n",
       " 'leaving',\n",
       " 'clan',\n",
       " 'miserable',\n",
       " 'suck',\n",
       " 'losers',\n",
       " 'come',\n",
       " 'sick',\n",
       " 'whores',\n",
       " 'contacting',\n",
       " 'your',\n",
       " 'dodgy',\n",
       " 'burned',\n",
       " 'nipples',\n",
       " 'garbage',\n",
       " 'recon',\n",
       " 'shit',\n",
       " 'scumbag',\n",
       " 'nearly',\n",
       " 'too',\n",
       " 'stupid',\n",
       " 'every',\n",
       " 'damn',\n",
       " 'bureaucratic',\n",
       " 'crap',\n",
       " 'your',\n",
       " 'problem',\n",
       " 'fucking',\n",
       " 'neighborhood',\n",
       " 'cheater',\n",
       " 'wretched',\n",
       " 'fucking',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_words_in_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bimba = texts[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". contemptuous xerxes blithely surrendered control to the computer grid, allowing it to take care of whatever troubles might arise..\n",
      ". that night, li'l had satisfied his thirst to die, though he knew she would never forgive him..\n",
      ". \" life starts the first time you die, too..\n",
      ". i think you are the strangest man i. ve ever met..\n",
      ". i mean creepy, i mean, it's totally batshit that i can even talk to you..\n",
      ". well, this one i can't even pronounce..\n",
      ". i like that one..\n",
      ". trying to keep me completely drugged so i don't know what's going on..\n",
      ". why is this not home? this is something that comes home..\n",
      ". hey, leave the girl girl alone!.\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "masked_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "for sentence in bimba:\n",
    "    # Tokenize the sentence\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True)\n",
    "\n",
    "    # Identify the toxic words and replace them with [MASK]\n",
    "    input_ids = inputs['input_ids'].tolist()[0]\n",
    "    for i in range(len(input_ids)):\n",
    "        if tokenizer.decode([input_ids[i]]) in toxic_words_in_sentences:\n",
    "            input_ids[i] = tokenizer.mask_token_id\n",
    "\n",
    "    # Convert back to tensors\n",
    "    inputs['input_ids'] = torch.tensor([input_ids])\n",
    "\n",
    "    # Predict the masked tokens\n",
    "    outputs = model(**inputs)\n",
    "    predictions = outputs.logits\n",
    "\n",
    "    # Get the predicted tokens\n",
    "    predicted_ids = torch.argmax(predictions, dim=2)\n",
    "\n",
    "    # Decode the tokens to strings\n",
    "    predicted_sentence = tokenizer.decode(predicted_ids[0])\n",
    "\n",
    "    print(predicted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatuous Xerxes blithely surrendered control to the computer grid , [MASK] it to take [MASK] of [MASK] troubles might arise .\n",
      "That night , Li ' l Dice satisfied his thirst to [MASK] , though he knew Shaggy would [MASK] forgive [MASK] .\n",
      "Real life starts the first time you [MASK] , [MASK] .\n",
      "I think you [MASK] the strangest man I ' ve ever [MASK] .\n",
      "I [MASK] creepy , I mean , it ' s totally batshit [MASK] I can even talk to you .\n",
      "Shit , this one I can ' t even pronounce .\n",
      "I like that [MASK] .\n",
      "Trying to keep me [MASK] drugged so I don ' t know what ' s [MASK] on .\n",
      "How is this not [MASK] ? This is [MASK] that comes home .\n",
      "Hey , leave the [MASK] [MASK] alone !\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "masked_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# For each sentence\n",
    "for i in range(len(bimba)):\n",
    "    # Tokenize the sentence into words and punctuation\n",
    "    tokens = re.findall(r\"\\b\\w+\\b|[\\.,!?']\", bimba[i])\n",
    "    \n",
    "    # Replace toxic words with [MASK]\n",
    "    for j in range(len(tokens)):\n",
    "        if tokens[j] in toxic_words_in_sentences:\n",
    "            tokens[j] = '[MASK]'\n",
    "    \n",
    "    # Join the tokens back into a sentence\n",
    "    bimba[i] = ' '.join(tokens)\n",
    "    \n",
    "    print(bimba[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatuous Xerxes blithely surrendered control to the computer grid , [MASK] it to take [MASK] of [MASK] troubles might arise .\n",
      "That night , Li ' l Dice satisfied his thirst to [MASK] , though he knew Shaggy would [MASK] forgive [MASK] .\n",
      "Real life starts the first time you [MASK] , [MASK] .\n",
      "I think you [MASK] the strangest man I ' ve ever [MASK] .\n",
      "I [MASK] creepy , I mean , it ' s totally batshit [MASK] I can even talk to you .\n",
      "Shit , this one I can ' t even pronounce .\n",
      "I like that [MASK] .\n",
      "Trying to keep me [MASK] drugged so I don ' t know what ' s [MASK] on .\n",
      "How is this not [MASK] ? This is [MASK] that comes home .\n",
      "Hey , leave the [MASK] [MASK] alone !\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\n    # Predict replacements for \\'[MASK]\\'\\n    inputs = tokenizer(tokens, return_tensors=\\'pt\\', padding=True, truncation=True)\\n    outputs = masked_model(**inputs)\\n    print(outputs)\\n    \\n    # Get predicted tokens and penalize tokens with positive toxicities\\n    logits = outputs.logits - token_toxicities * inputs[\\'input_ids\\']\\n    preds = torch.argmax(logits, dim=-1)\\n    \\n    # Replace \\'[MASK]\\' with predicted tokens and rerank by similarity of embeddings\\n    for j in toxic_word_indices:\\n        inputs.input_ids[0][j] = preds[0][j]\\n    \\n    # Decode the tokens back into a sentence\\n    texts[i] = tokenizer.decode(inputs.input_ids[0])\\n# For each sentence in \\'bimba\\'\\nfor i in range(len(bimba)):\\n    # Tokenize the sentence into words and punctuation\\n    tokens = re.findall(r\"\\x08\\\\w+\\x08|[\\\\.,!?\\']\", bimba[i])\\n    \\n    # Identify toxic words\\n    toxic_word_indices = [j for j in range(len(tokens)) if tokens[j] in toxic_words_in_sentences]\\n    \\n    # Replace toxic words with [MASK] and preserve original tokens\\n    original_tokens = tokens.copy()\\n    for j in toxic_word_indices:\\n        tokens[j] = \\'[MASK]\\'\\n    \\n    # Join the tokens back into a sentence\\n    bimba[i] = \\' \\'.join(tokens)\\n    \\n    print(bimba[i])\\n    \\n    # Predict replacements for \\'[MASK]\\'\\n    inputs = tokenizer(tokens, return_tensors=\\'pt\\', padding=True, truncation=True)\\n    outputs = masked_model(**inputs)\\n    \\n    # Get predicted tokens and penalize tokens with positive toxicities\\n    toxicity_scores = torch.tensor([token_toxicities.get(token.item(), 0) for token in inputs[\\'input_ids\\'][0]], dtype=torch.float)\\n    toxicity_scores = toxicity_scores.unsqueeze(0).unsqueeze(2)\\n    logits = outputs.logits - toxicity_scores\\n    preds = torch.argmax(logits, dim=-1)\\n    \\n    # Replace \\'[MASK]\\' with predicted tokens and rerank by similarity of embeddings\\n    mask_indices = (inputs.input_ids[0] == tokenizer.mask_token_id).nonzero(as_tuple=True)[0]\\n    for j, mask_index in enumerate(mask_indices):\\n        inputs.input_ids[0][mask_index] = preds[0][j]\\n\\n    # Decode the tokens back into a sentence\\n    decoded_sentence = tokenizer.decode(inputs.input_ids[0], skip_special_tokens=True)\\n    print(decoded_sentence, 1743)\\n    '"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bimba = texts[20:30]\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "masked_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Create a dictionary mapping tokens to their toxicity scores\n",
    "token_toxicities = {tokenizer.encode(word, add_special_tokens=False)[0]: 1 for word in toxic_words_in_sentences}\n",
    "\n",
    "\n",
    "# For each sentence in 'bimba'\n",
    "for i in range(len(bimba)):\n",
    "    # Tokenize the sentence into words and punctuation\n",
    "    tokens = re.findall(r\"\\b\\w+\\b|[\\.,!?']\", bimba[i])\n",
    "    \n",
    "    # Identify toxic words\n",
    "    toxic_word_indices = [j for j in range(len(tokens)) if tokens[j] in toxic_words_in_sentences]\n",
    "    \n",
    "    # Replace toxic words with [MASK] and preserve original tokens\n",
    "    original_tokens = tokens.copy()\n",
    "    for j in toxic_word_indices:\n",
    "        tokens[j] = '[MASK]'\n",
    "    \n",
    "    # Join the tokens back into a sentence\n",
    "    bimba[i] = ' '.join(tokens)\n",
    "    \n",
    "    print(bimba[i])\n",
    "''' \n",
    "    # Predict replacements for '[MASK]'\n",
    "    inputs = tokenizer(tokens, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = masked_model(**inputs)\n",
    "    print(outputs)\n",
    "    \n",
    "    # Get predicted tokens and penalize tokens with positive toxicities\n",
    "    logits = outputs.logits - token_toxicities * inputs['input_ids']\n",
    "    preds = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    # Replace '[MASK]' with predicted tokens and rerank by similarity of embeddings\n",
    "    for j in toxic_word_indices:\n",
    "        inputs.input_ids[0][j] = preds[0][j]\n",
    "    \n",
    "    # Decode the tokens back into a sentence\n",
    "    texts[i] = tokenizer.decode(inputs.input_ids[0])\n",
    "# For each sentence in 'bimba'\n",
    "for i in range(len(bimba)):\n",
    "    # Tokenize the sentence into words and punctuation\n",
    "    tokens = re.findall(r\"\\b\\w+\\b|[\\.,!?']\", bimba[i])\n",
    "    \n",
    "    # Identify toxic words\n",
    "    toxic_word_indices = [j for j in range(len(tokens)) if tokens[j] in toxic_words_in_sentences]\n",
    "    \n",
    "    # Replace toxic words with [MASK] and preserve original tokens\n",
    "    original_tokens = tokens.copy()\n",
    "    for j in toxic_word_indices:\n",
    "        tokens[j] = '[MASK]'\n",
    "    \n",
    "    # Join the tokens back into a sentence\n",
    "    bimba[i] = ' '.join(tokens)\n",
    "    \n",
    "    print(bimba[i])\n",
    "    \n",
    "    # Predict replacements for '[MASK]'\n",
    "    inputs = tokenizer(tokens, return_tensors='pt', padding=True, truncation=True)\n",
    "    outputs = masked_model(**inputs)\n",
    "    \n",
    "    # Get predicted tokens and penalize tokens with positive toxicities\n",
    "    toxicity_scores = torch.tensor([token_toxicities.get(token.item(), 0) for token in inputs['input_ids'][0]], dtype=torch.float)\n",
    "    toxicity_scores = toxicity_scores.unsqueeze(0).unsqueeze(2)\n",
    "    logits = outputs.logits - toxicity_scores\n",
    "    preds = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "    # Replace '[MASK]' with predicted tokens and rerank by similarity of embeddings\n",
    "    mask_indices = (inputs.input_ids[0] == tokenizer.mask_token_id).nonzero(as_tuple=True)[0]\n",
    "    for j, mask_index in enumerate(mask_indices):\n",
    "        inputs.input_ids[0][mask_index] = preds[0][j]\n",
    "\n",
    "    # Decode the tokens back into a sentence\n",
    "    decoded_sentence = tokenizer.decode(inputs.input_ids[0], skip_special_tokens=True)\n",
    "    print(decoded_sentence, 1743)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bad-words.txt\", \"r\") as f:\n",
    "    s = f.readlines()\n",
    "negative_words = list(map(lambda x: x[:-1], s))\n",
    "\n",
    "with open(\"good-words.txt\", \"r\") as f:\n",
    "    s = f.readlines()\n",
    "positive_words = list(map(lambda x: x[:-1], s))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MaskedTokenPredictorBert' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [168]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madjust_logits\u001b[39m(logits, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m logits \u001b[38;5;241m-\u001b[39m token_toxicities \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m label)\n\u001b[1;32m----> 8\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mMaskedTokenPredictorBert\u001b[49m(masked_model, tokenizer, max_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m250\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m      9\u001b[0m                                      contrast_penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m, logits_postprocessor\u001b[38;5;241m=\u001b[39madjust_logits)\n\u001b[0;32m     11\u001b[0m editor \u001b[38;5;241m=\u001b[39m CondBertRewriter(\n\u001b[0;32m     12\u001b[0m     model\u001b[38;5;241m=\u001b[39mmasked_model,\n\u001b[0;32m     13\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m     predictor\u001b[38;5;241m=\u001b[39mpredictor,\n\u001b[0;32m     20\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MaskedTokenPredictorBert' is not defined"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "masked_model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def adjust_logits(logits, label=0):\n",
    "    return logits - token_toxicities * 100 * (1 - 2 * label)\n",
    "\n",
    "predictor = MaskedTokenPredictorBert(masked_model, tokenizer, max_len=250, device=device, label=0,\n",
    "                                     contrast_penalty=0.0, logits_postprocessor=adjust_logits)\n",
    "\n",
    "editor = CondBertRewriter(\n",
    "    model=masked_model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device,\n",
    "    neg_words=negative_words,\n",
    "    pos_words=positive_words,\n",
    "    word2coef=word_toxicity_scores,\n",
    "    token_toxicities=word_toxicity_scores,\n",
    "    predictor=predictor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fatuous Xerxes blithely surrendered control to the computer grid, ordering it to take care of whatever troubles might arise.',\n",
       " \"That night, Li'l Dice satisfied his thirst to kill, though he knew Shaggy would never forgive him.\",\n",
       " 'Real life starts the first time you fuck, kid.',\n",
       " \"I think you are the strangest man I've ever met.\",\n",
       " \"I say creepy, I mean, it's totally batshit crazy I can even talk to you.\",\n",
       " \"Shit, this one I can't even pronounce.\",\n",
       " 'I like that shit.',\n",
       " \"Trying to keep me fucking drugged so I don't know what's going on.\",\n",
       " 'How is this not porn? This is porn that comes home.',\n",
       " 'Hey, leave the poor bastard alone!']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] fatuous [SEP] [PAD] [PAD]',\n",
       " '[CLS] that [SEP]',\n",
       " '[CLS] real [SEP]',\n",
       " '[CLS] i [SEP] [PAD]',\n",
       " '[CLS] i [SEP] [PAD]',\n",
       " '[CLS] shit [SEP] [PAD] [PAD]',\n",
       " '[CLS] i [SEP]',\n",
       " '[CLS] trying [SEP]',\n",
       " '[CLS] how [SEP]',\n",
       " '[CLS] hey [SEP]']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bimba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
